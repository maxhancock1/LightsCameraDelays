{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取训练集和测试集的 CSV 文件\n",
    "ratings_train = pd.read_csv(\"ratings_train.csv\")\n",
    "ratings_test = pd.read_csv(\"ratings_test.csv\")\n",
    "movies = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "# 查看数据结构\n",
    "print(\"ratings_train 数据结构:\")\n",
    "print(ratings_train.info())  # 展示数据的总体结构\n",
    "\n",
    "\n",
    "print(\"\\nratings_test 数据结构:\")\n",
    "print(ratings_test.info())\n",
    "\n",
    "\n",
    "print(\"\\nmovies 数据结构:\")\n",
    "print(movies.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单查看数据\n",
    "print(movies.head())\n",
    "print(ratings_train.head())\n",
    "print(ratings_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 timestamp 列转换为时间戳（如果它是日期格式）\n",
    "ratings_train['timestamp'] = pd.to_datetime(ratings_train['timestamp'])\n",
    "ratings_train['timestamp'] = ratings_train['timestamp'].view('int64') / 10**9  # 转换为秒级时间戳\n",
    "\n",
    "# 计算皮尔逊相关系数\n",
    "correlation = ratings_train['timestamp'].corr(ratings_train['rating'])\n",
    "\n",
    "print(\"Timestamp 和 Rating 之间的相关度:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_1 = pd.merge(ratings_train, movies, on='movieId', how='outer')\n",
    "merged_1.to_csv('merged_1.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_2 = pd.merge(ratings_train, movies, on='movieId', how='inner')\n",
    "merged_2.to_csv('merged_2.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取 ratings_train 和 movies 数据\n",
    "ratings_train = pd.read_csv('ratings_train.csv', encoding='utf-8')\n",
    "movies = pd.read_csv('movies.csv', encoding='utf-8')\n",
    "\n",
    "# 将 ratings_train 中的 timestamp（float64，即 Unix 时间戳）转换为 datetime 格式\n",
    "ratings_train['timestamp'] = pd.to_datetime(ratings_train['timestamp'], unit='s')\n",
    "\n",
    "# 使用已经转换好的 timestamp 生成日期，并提取年月信息\n",
    "ratings_train['year_month'] = ratings_train['timestamp'].dt.to_period('M')\n",
    "\n",
    "# 检查 year_month 列\n",
    "print(\"Year-Month column:\")\n",
    "print(ratings_train[['timestamp', 'year_month']].head())\n",
    "\n",
    "# 拆分 genres 列，这里以字母 'I' 作为分隔符\n",
    "movies['genre_list'] = movies['genres'].str.split('|')\n",
    "\n",
    "# 展开 genres 列并清理数据\n",
    "movies_exploded = movies.explode('genre_list').rename(columns={'genre_list': 'genre'})\n",
    "\n",
    "# 检查拆分结果\n",
    "print(\"Exploded Movies DataFrame:\")\n",
    "print(movies_exploded[['movieId', 'genres', 'genre']].head())\n",
    "\n",
    "# 在 ratings_train 和 movies_exploded 中分别提取 movieId 对应的数据\n",
    "# 将 ratings_train 的每个 movieId 对应的 genre 从 movies_exploded 中获取\n",
    "df = pd.merge(ratings_train, movies_exploded[['movieId', 'genre']], on='movieId', how='inner')\n",
    "\n",
    "# 按每个月和每个 genre 分组，计算平均 rating\n",
    "monthly_avg = df.groupby(['year_month', 'genre'])['rating'].mean().reset_index()\n",
    "\n",
    "# 打印计算结果\n",
    "print(\"Monthly Average:\")\n",
    "print(monthly_avg.head())\n",
    "\n",
    "# 绘制每个 genre 的评分变化图\n",
    "if not monthly_avg.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for genre in monthly_avg['genre'].unique():\n",
    "        genre_data = monthly_avg[monthly_avg['genre'] == genre]\n",
    "        plt.plot(genre_data['year_month'].astype(str), genre_data['rating'], label=genre)\n",
    "\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.title('Average Rating per Genre over Time')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Genre')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 读取 ratings_train 和 movies 数据\n",
    "ratings_train = pd.read_csv('ratings_train.csv', encoding='utf-8')\n",
    "movies = pd.read_csv('movies.csv', encoding='utf-8')\n",
    "\n",
    "# 将 ratings_train 中的 timestamp 转换为 datetime 格式，并提取年份\n",
    "ratings_train['timestamp'] = pd.to_datetime(ratings_train['timestamp'], unit='s')\n",
    "ratings_train['year'] = ratings_train['timestamp'].dt.year\n",
    "\n",
    "# 拆分 movies 中的 genres 列，使用字母 'I' 作为分隔符\n",
    "movies['genre_list'] = movies['genres'].str.split('|')\n",
    "movies_exploded = movies.explode('genre_list').rename(columns={'genre_list': 'genre'})\n",
    "\n",
    "# 通过 movieId 将 ratings_train 和 movies_exploded 数据关联起来\n",
    "df = pd.merge(ratings_train, movies_exploded[['movieId', 'genre']], on='movieId', how='inner')\n",
    "\n",
    "# 按每年和每个 genre 分组，计算平均 rating\n",
    "yearly_avg = df.groupby(['year', 'genre'])['rating'].mean().reset_index()\n",
    "\n",
    "# 指定保存图片的路径\n",
    "save_path = r\"C:\\Users\\C\\Desktop\\SML\\Project 2\\TS\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# 针对每个 genre 单独生成图表\n",
    "for genre in yearly_avg['genre'].unique():\n",
    "    # 筛选当前 genre 的数据，并按年份排序\n",
    "    genre_data = yearly_avg[yearly_avg['genre'] == genre].sort_values('year')\n",
    "    \n",
    "    # 准备 x 轴：将年份转换为字符串\n",
    "    x_labels = genre_data['year'].astype(str)\n",
    "    x_positions = range(len(x_labels))\n",
    "    y_values = genre_data['rating']\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # 绘制评分曲线\n",
    "    plt.plot(x_positions, y_values, marker='o', linestyle='-', label=genre)\n",
    "    \n",
    "    # 计算该 genre 的总平均 rating，并绘制水平基准线\n",
    "    overall_avg = df[df['genre'] == genre]['rating'].mean()\n",
    "    plt.axhline(y=overall_avg, color='red', linestyle='--', label=f'Overall Avg: {overall_avg:.2f}')\n",
    "    \n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.title(f'Average Rating Trend for {genre}')\n",
    "    plt.xticks(x_positions, x_labels, rotation=45)\n",
    "    plt.legend(title='Legend')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存图像到指定目录，文件名为 \"{genre}_rating_trend.png\"\n",
    "    plt.savefig(os.path.join(save_path, f\"{genre}_rating_trend.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找特定记录\n",
    "user_records = merged_1[merged_1['movieId'] == 147426]\n",
    "print(user_records)\n",
    "\n",
    "# 查找符合多个条件的记录\n",
    "filtered_records = ratings_train[(ratings_train['userId'] == 5) & (ratings_train['movieId'] == 32)]\n",
    "print(filtered_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ratings_train and ratings_test are pandas DataFrames\n",
    "known_users = ratings_train['userId'].unique()\n",
    "known_movies = ratings_train['movieId'].unique()\n",
    "\n",
    "test_users = ratings_test['userId'].unique()\n",
    "test_movies = ratings_test['movieId'].unique()\n",
    "\n",
    "cold_start_users = sum(~pd.Series(test_users).isin(known_users))\n",
    "cold_start_movies = sum(~pd.Series(test_movies).isin(known_movies))\n",
    "\n",
    "print(cold_start_users)  # Cold start users count\n",
    "print(cold_start_movies)  # Cold start movies count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 数据加载函数\n",
    "def load_data():\n",
    "    # 加载单个文件数据\n",
    "    data = pd.read_csv('merged_1.csv')  # 确保文件名称与实际一致\n",
    "    return data\n",
    "\n",
    "\n",
    "# 构建用户-电影评分矩阵\n",
    "def create_user_movie_matrix(data):\n",
    "    \"\"\"\n",
    "    从完整的数据构建用户-电影的评分矩阵\n",
    "    \"\"\"\n",
    "    user_movie_matrix = data.pivot(index='userId', columns='movieId', values='rating')\n",
    "    user_movie_matrix.fillna(0, inplace=True)  # 将缺失值（未评分）填充为 0\n",
    "    return user_movie_matrix\n",
    "\n",
    "\n",
    "# 矩阵分解 (梯度下降法) 带早停机制\n",
    "def matrix_factorization_with_early_stopping(R, K, steps, alpha=0.002, lambda_reg=0.1, patience=10, tolerance=0.001):\n",
    "    \"\"\"\n",
    "    矩阵分解 (随机梯度下降) 带早停机制\n",
    "    参数:\n",
    "        R: 用户-电影评分矩阵\n",
    "        K: 潜在因子维度\n",
    "        steps: 最大迭代次数\n",
    "        alpha: 学习率\n",
    "        lambda_reg: 正则化参数\n",
    "        patience: 早停容忍次数\n",
    "        tolerance: 损失改善的最低阈值（提升小于该值时认为没有改善）\n",
    "    返回:\n",
    "        P: 用户特征矩阵\n",
    "        Q: 电影特征矩阵\n",
    "        best_loss: 最佳损失值\n",
    "    \"\"\"\n",
    "    num_users, num_movies = R.shape\n",
    "    P = np.random.rand(num_users, K)  # 初始化用户特征矩阵\n",
    "    Q = np.random.rand(num_movies, K)  # 初始化电影特征矩阵\n",
    "    \n",
    "    best_loss = float('inf')  # 最佳损失\n",
    "    patience_counter = 0  # 早停计数器\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # 随机梯度更新\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if R[i, j] > 0:  # 仅更新有评分的数据点\n",
    "                    eij = R[i, j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                    for k in range(K):\n",
    "                        P[i, k] += alpha * (2 * eij * Q[j, k] - lambda_reg * P[i, k])\n",
    "                        Q[j, k] += alpha * (2 * eij * P[i, k] - lambda_reg * Q[j, k])\n",
    "        \n",
    "        # 每步计算当前的总误差\n",
    "        loss = 0\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if R[i, j] > 0:\n",
    "                    loss += (R[i, j] - np.dot(P[i, :], Q[j, :].T)) ** 2\n",
    "        \n",
    "        # 打印每隔多步的损失\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Iteration {step}/{steps} => Loss: {loss:.4f}\")\n",
    "        \n",
    "        # 检查是否早停\n",
    "        if loss < best_loss - tolerance:  # 损失有显著改善\n",
    "            best_loss = loss\n",
    "            patience_counter = 0  # 重置早停计数器\n",
    "        else:  # 损失没有改善\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience {patience_counter}/{patience}: No significant improvement in loss.\")\n",
    "\n",
    "        if patience_counter >= patience:  # 提前停止\n",
    "            print(f\"Early stopping triggered. Best loss: {best_loss:.4f}\")\n",
    "            break\n",
    "    \n",
    "    return P, Q, best_loss\n",
    "\n",
    "\n",
    "# 获取预测评分\n",
    "def get_predictions(data, P, Q, user_id_mapping, movie_id_mapping):\n",
    "    \"\"\"\n",
    "    为每个用户预测评分，并将其调整为 0 到 5 且以 0.5 为间隔\n",
    "    \"\"\"\n",
    "    data['predicted_rating'] = data.apply(\n",
    "        lambda row: round_rating(\n",
    "            np.dot(P[user_id_mapping[row['userId']], :], Q[movie_id_mapping[row['movieId']], :].T)\n",
    "        ) if row['userId'] in user_id_mapping and row['movieId'] in movie_id_mapping else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# 新增函数： 四舍五入到最近 0.5\n",
    "def round_rating(rating):\n",
    "    \"\"\"\n",
    "    将预测评分四舍五入到最近的 0.5 并裁剪到 [0, 5]\n",
    "    参数:\n",
    "        rating: 预测评分\n",
    "    返回:\n",
    "        调整后的评分\n",
    "    \"\"\"\n",
    "    rating = round(rating * 2) / 2  # 四舍五入到最近的 0.5\n",
    "    return np.clip(rating, 0, 5)  # 限制在 0 到 5 范围内\n",
    "\n",
    "# 替换主程序调用矩阵分解的部分\n",
    "def main1():\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data()  # 加载新数据集\n",
    "\n",
    "    print(\"\\nCreating user-movie matrix...\")\n",
    "    user_movie_matrix = create_user_movie_matrix(data)\n",
    "\n",
    "    # 获取用户和电影映射字典\n",
    "    user_id_mapping = {id: idx for idx, id in enumerate(user_movie_matrix.index)}\n",
    "    movie_id_mapping = {id: idx for idx, id in enumerate(user_movie_matrix.columns)}\n",
    "\n",
    "    print(\"Training Matrix Factorization Model...\")\n",
    "    latent_factors = 10  # 潜在因子数量\n",
    "    patience = 20  # 早停容忍次数\n",
    "    tolerance = 0.0001  # 损失改善的最低阈值\n",
    "    \n",
    "    P, Q, best_loss = matrix_factorization_with_early_stopping(\n",
    "        user_movie_matrix.to_numpy(), \n",
    "        K=latent_factors, \n",
    "        steps=1000, \n",
    "        alpha=0.002, \n",
    "        lambda_reg=0.1, \n",
    "        patience=patience, \n",
    "        tolerance=tolerance\n",
    "    )\n",
    "    print(f\"\\nMatrix Factorization Training Completed! Best Loss: {best_loss:.4f}\")\n",
    "\n",
    "    # 保存结果\n",
    "    print(\"Saving trained matrices and mappings for testing...\")\n",
    "    np.save('P_matrix.npy', P)\n",
    "    np.save('Q_matrix.npy', Q)\n",
    "    np.save('user_id_mapping.npy', user_id_mapping)\n",
    "    np.save('movie_id_mapping.npy', movie_id_mapping)\n",
    "\n",
    "    # 计算全局平均评分并保存\n",
    "    global_avg_rating = np.mean(data['rating'])\n",
    "    np.save('global_avg_rating.npy', global_avg_rating)\n",
    "\n",
    "    print(\"Training data has been saved successfully.\")\n",
    "    \n",
    "    # print(\"Predicting User Ratings...\")\n",
    "    # # 新列包含预测评分\n",
    "    # data_with_predictions = get_predictions(data, P, Q, user_id_mapping, movie_id_mapping)\n",
    "\n",
    "    # # 保存结果到文件\n",
    "    # output_file = 'film_rating_predictions_group_E_week_Y.csv'\n",
    "    # data_with_predictions.to_csv(output_file, index=False)\n",
    "    # print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "    # # 计算均方误差（可选）\n",
    "    # mask = ~data_with_predictions['predicted_rating'].isna()  # 筛选出有效数据\n",
    "    # mse = mean_squared_error(data_with_predictions[mask]['rating'], data_with_predictions[mask]['predicted_rating'])\n",
    "    # print(f\"Mean Squared Error (MSE) on Train Data: {mse:.4f}\")\n",
    "\n",
    "main1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 四舍五入到最近的 0.5 且裁剪到 [0, 5]\n",
    "def round_rating(rating):\n",
    "    \"\"\"\n",
    "    四舍五入评分到最近的 0.5，然后裁剪到 [0, 5] 的范围\n",
    "    参数:\n",
    "        rating: 预测的评分值\n",
    "    返回:\n",
    "        四舍五入且裁剪后的评分\n",
    "    \"\"\"\n",
    "    rating = round(rating * 2) / 2  # 四舍五入到最近的 0.5\n",
    "    return np.clip(rating, 0, 5)  # 限制到 [0, 5]\n",
    "\n",
    "\n",
    "# 加载测试数据\n",
    "def load_test_data(file_path):\n",
    "    \"\"\"\n",
    "    加载测试数据集\n",
    "    参数:\n",
    "        file_path: 测试文件路径\n",
    "    返回:\n",
    "        测试数据 (dataframe)\n",
    "    \"\"\"\n",
    "    ratings_test = pd.read_csv(file_path, sep=',')  # 加载测试数据\n",
    "    return ratings_test\n",
    "\n",
    "\n",
    "# 预测测试集中评分\n",
    "def predict_test_ratings(test_data, P, Q, user_id_mapping, movie_id_mapping, global_avg_rating):\n",
    "    \"\"\"\n",
    "    预测测试数据集中的评分\n",
    "    参数:\n",
    "        test_data: 测试数据集 (dataframe)，包含 userId 和 movieId\n",
    "        P: 用户特征矩阵 (m x latent_factors)\n",
    "        Q: 电影特征矩阵 (n x latent_factors)\n",
    "        user_id_mapping: 用户 ID 映射到 P 的索引\n",
    "        movie_id_mapping: 电影 ID 映射到 Q 的索引\n",
    "        global_avg_rating: 训练集全局平均评分（作为冷启动策略时用）\n",
    "    返回:\n",
    "        测试数据集中预测的评分列表\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for _, row in test_data.iterrows():\n",
    "        user_id = row['userId']\n",
    "        movie_id = row['movieId']\n",
    "        \n",
    "        # 如果用户和电影在训练集中，使用矩阵分解结果预测评分\n",
    "        if user_id in user_id_mapping and movie_id in movie_id_mapping:\n",
    "            user_idx = user_id_mapping[user_id]\n",
    "            movie_idx = movie_id_mapping[movie_id]\n",
    "            predicted_rating = np.dot(P[user_idx, :], Q[movie_idx, :].T)\n",
    "        else:\n",
    "            # 冷启动策略：使用全局平均评分\n",
    "            predicted_rating = global_avg_rating\n",
    "        \n",
    "        # 四舍五入到 0.5 并裁剪到 [0, 5]\n",
    "        predictions.append(round_rating(predicted_rating))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "# 主函数\n",
    "def main2():\n",
    "    print(\"Loading test data...\")\n",
    "    ratings_test = load_test_data('ratings_test.csv')  # 确保测试文件路径正确\n",
    "\n",
    "    print(\"Loading pre-trained model...\")\n",
    "    # 加载已保存的模型\n",
    "    try:\n",
    "        P = np.load('P_matrix.npy')\n",
    "        Q = np.load('Q_matrix.npy')\n",
    "        user_id_mapping = np.load('user_id_mapping.npy', allow_pickle=True).item()\n",
    "        movie_id_mapping = np.load('movie_id_mapping.npy', allow_pickle=True).item()\n",
    "        global_avg_rating = np.load('global_avg_rating.npy')  # 加载全局平均评分\n",
    "        print(\"Pre-trained model successfully loaded.\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Model file missing: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Test Data Shape: {ratings_test.shape}\")\n",
    "    print(\"Predicting ratings on the test set...\")\n",
    "\n",
    "    # 调用预测函数\n",
    "    ratings_test['predicted_rating'] = predict_test_ratings(\n",
    "        ratings_test, P, Q, user_id_mapping, movie_id_mapping, global_avg_rating\n",
    "    )\n",
    "\n",
    "    # 保存预测结果到文件\n",
    "    output_file = 'film_rating_predictions_group_E_week_.csv'\n",
    "    ratings_test.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to '{output_file}'.\")\n",
    "\n",
    "    # （可选）评估模型性能：如果测试集有真实评分\n",
    "    if 'rating' in ratings_test.columns:\n",
    "        mse = mean_squared_error(ratings_test['rating'], ratings_test['predicted_rating'])\n",
    "        print(f\"Mean Squared Error (MSE) on Test Data: {mse:.4f}\")\n",
    "\n",
    "\n",
    "# 运行主函数\n",
    "main2()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 数据加载函数\n",
    "def load_data():\n",
    "    # 加载单个文件数据\n",
    "    data = pd.read_csv('merged_1.csv')  # 确保文件名称与实际一致\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_user_movie_matrix(data):\n",
    "    \"\"\"\n",
    "    从完整的数据构建用户-电影的评分矩阵\n",
    "    \"\"\"\n",
    "    user_movie_matrix = data.pivot(index='userId', columns='movieId', values='rating')\n",
    "    # 删除包含缺失值的记录\n",
    "    user_movie_matrix.dropna(inplace=True)\n",
    "    return user_movie_matrix\n",
    "\n",
    "\n",
    "\n",
    "# 矩阵分解 (梯度下降法) 带早停机制\n",
    "def matrix_factorization_with_early_stopping(R, K, steps, alpha=0.002, lambda_reg=0.1, patience=10, tolerance=0.001):\n",
    "    \"\"\"\n",
    "    矩阵分解 (随机梯度下降) 带早停机制\n",
    "    参数:\n",
    "        R: 用户-电影评分矩阵\n",
    "        K: 潜在因子维度\n",
    "        steps: 最大迭代次数\n",
    "        alpha: 学习率\n",
    "        lambda_reg: 正则化参数\n",
    "        patience: 早停容忍次数\n",
    "        tolerance: 损失改善的最低阈值（提升小于该值时认为没有改善）\n",
    "    返回:\n",
    "        P: 用户特征矩阵\n",
    "        Q: 电影特征矩阵\n",
    "        best_loss: 最佳损失值\n",
    "    \"\"\"\n",
    "    num_users, num_movies = R.shape\n",
    "    P = np.random.rand(num_users, K)  # 初始化用户特征矩阵\n",
    "    Q = np.random.rand(num_movies, K)  # 初始化电影特征矩阵\n",
    "    \n",
    "    best_loss = float('inf')  # 最佳损失\n",
    "    patience_counter = 0  # 早停计数器\n",
    "    \n",
    "    for step in range(steps):\n",
    "        # 随机梯度更新\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if R[i, j] > 0:  # 仅更新有评分的数据点\n",
    "                    eij = R[i, j] - np.dot(P[i, :], Q[j, :].T)\n",
    "                    for k in range(K):\n",
    "                        P[i, k] += alpha * (2 * eij * Q[j, k] - lambda_reg * P[i, k])\n",
    "                        Q[j, k] += alpha * (2 * eij * P[i, k] - lambda_reg * Q[j, k])\n",
    "        \n",
    "        # 每步计算当前的总误差\n",
    "        loss = 0\n",
    "        for i in range(num_users):\n",
    "            for j in range(num_movies):\n",
    "                if R[i, j] > 0:\n",
    "                    loss += (R[i, j] - np.dot(P[i, :], Q[j, :].T)) ** 2\n",
    "        \n",
    "        # 打印每隔多步的损失\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Iteration {step}/{steps} => Loss: {loss:.4f}\")\n",
    "        \n",
    "        # 检查是否早停\n",
    "        if loss < best_loss - tolerance:  # 损失有显著改善\n",
    "            best_loss = loss\n",
    "            patience_counter = 0  # 重置早停计数器\n",
    "        else:  # 损失没有改善\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience {patience_counter}/{patience}: No significant improvement in loss.\")\n",
    "\n",
    "        if patience_counter >= patience:  # 提前停止\n",
    "            print(f\"Early stopping triggered. Best loss: {best_loss:.4f}\")\n",
    "            break\n",
    "    \n",
    "    return P, Q, best_loss\n",
    "\n",
    "\n",
    "# 获取预测评分\n",
    "def get_predictions(data, P, Q, user_id_mapping, movie_id_mapping):\n",
    "    \"\"\"\n",
    "    为每个用户预测评分，并将其调整为 0 到 5 且以 0.5 为间隔\n",
    "    \"\"\"\n",
    "    data['predicted_rating'] = data.apply(\n",
    "        lambda row: round_rating(\n",
    "            np.dot(P[user_id_mapping[row['userId']], :], Q[movie_id_mapping[row['movieId']], :].T)\n",
    "        ) if row['userId'] in user_id_mapping and row['movieId'] in movie_id_mapping else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    return data\n",
    "\n",
    "# 新增函数： 四舍五入到最近 0.5\n",
    "def round_rating(rating):\n",
    "    \"\"\"\n",
    "    将预测评分四舍五入到最近的 0.5 并裁剪到 [0, 5]\n",
    "    参数:\n",
    "        rating: 预测评分\n",
    "    返回:\n",
    "        调整后的评分\n",
    "    \"\"\"\n",
    "    rating = round(rating * 2) / 2  # 四舍五入到最近的 0.5\n",
    "    return np.clip(rating, 0, 5)  # 限制在 0 到 5 范围内\n",
    "\n",
    "# 替换主程序调用矩阵分解的部分\n",
    "def main1():\n",
    "    print(\"Loading data...\")\n",
    "    data = load_data()  # 加载新数据集\n",
    "\n",
    "    print(\"\\nCreating user-movie matrix...\")\n",
    "    user_movie_matrix = create_user_movie_matrix(data)\n",
    "\n",
    "    # 获取用户和电影映射字典\n",
    "    user_id_mapping = {id: idx for idx, id in enumerate(user_movie_matrix.index)}\n",
    "    movie_id_mapping = {id: idx for idx, id in enumerate(user_movie_matrix.columns)}\n",
    "\n",
    "    print(\"Training Matrix Factorization Model...\")\n",
    "    latent_factors = 10  # 潜在因子数量\n",
    "    patience = 20  # 早停容忍次数\n",
    "    tolerance = 0.0001  # 损失改善的最低阈值\n",
    "    \n",
    "    P, Q, best_loss = matrix_factorization_with_early_stopping(\n",
    "        user_movie_matrix.to_numpy(), \n",
    "        K=latent_factors, \n",
    "        steps=1000, \n",
    "        alpha=0.002, \n",
    "        lambda_reg=0.1, \n",
    "        patience=patience, \n",
    "        tolerance=tolerance\n",
    "    )\n",
    "    print(f\"\\nMatrix Factorization Training Completed! Best Loss: {best_loss:.4f}\")\n",
    "\n",
    "    # 保存结果\n",
    "    print(\"Saving trained matrices and mappings for testing...\")\n",
    "    np.save('P_matrix.npy', P)\n",
    "    np.save('Q_matrix.npy', Q)\n",
    "    np.save('user_id_mapping.npy', user_id_mapping)\n",
    "    np.save('movie_id_mapping.npy', movie_id_mapping)\n",
    "\n",
    "    # 计算全局平均评分并保存\n",
    "    global_avg_rating = np.mean(data['rating'])\n",
    "    np.save('global_avg_rating.npy', global_avg_rating)\n",
    "\n",
    "    print(\"Training data has been saved successfully.\")\n",
    "    \n",
    "    # print(\"Predicting User Ratings...\")\n",
    "    # # 新列包含预测评分\n",
    "    # data_with_predictions = get_predictions(data, P, Q, user_id_mapping, movie_id_mapping)\n",
    "\n",
    "    # # 保存结果到文件\n",
    "    # output_file = 'film_rating_predictions_group_E_week_Y.csv'\n",
    "    # data_with_predictions.to_csv(output_file, index=False)\n",
    "    # print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "    # # 计算均方误差（可选）\n",
    "    # mask = ~data_with_predictions['predicted_rating'].isna()  # 筛选出有效数据\n",
    "    # mse = mean_squared_error(data_with_predictions[mask]['rating'], data_with_predictions[mask]['predicted_rating'])\n",
    "    # print(f\"Mean Squared Error (MSE) on Train Data: {mse:.4f}\")\n",
    "\n",
    "main1()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
